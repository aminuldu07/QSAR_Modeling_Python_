{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Partial Least Squares Models\n",
    "\n",
    "\n",
    "This is the second notebook in a series of Jupyter Notebooks linked to the project titled \"__Developing Mechanism-Based Models for Complex Toxicology Study Endpoints Using Standardized Electronic Submission Data__\".  The first notebook that creates the training set should be run before this one.  \n",
    "\n",
    "This notebook requires a dependcy script, `pls_logistic.py`.\n",
    "\n",
    "Partial least squares [(Wikipedia entry)](https://en.wikipedia.org/wiki/Partial_least_squares_regression) is a regression modeling technique that models the variance in X with the variance in y.  Since it is a regression technique and we are doing classification, we couple a logistic function to the output of the regression to bound it to be between [0, 1].  Because scikit-learn does not have this feature natively, I extened the scikit-learn classifier to a new class called `PLSLogistic`.  \n",
    "\n",
    "It is also required that we make this more of a true calibrated classifier by using the `CalibratedClassifier` functionality [described here](https://scikit-learn.org/stable/modules/calibration.html).\n",
    "\n",
    "The models are validated by using 10-fold cross validation. \n",
    "\n",
    "All of the clinical chemistry features are first log-transformed, then mean-centered and variance scaled.  All clinical chemistry tests where at least 40% of the responses are not null are used for modeling.  Null values are replaced with the mean for that feature.  \n",
    "\n",
    "Because PLSRegression does not do great with imbalanced data sets, a set of models is created for each liver disease phenotype.  This is done by an oversampling of the disease positive animals for that class.  This is done by creating _n_-models for with balanced disease positive/disease negative animals by taking random samples of the disease negative animals, until each animal has been used at least once in a model.  The overall modeling workflow is listed in the below figure. \n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"../img/modeling_workflow_figure.png\" width=\"1000\">\n",
    "</div>\n",
    "\n",
    "Each model is validated using 10-fold cross validation, assigned a unique identifier, and saved as a pickled object.  There is also a `params.csv` file that lists the specified parameters used to train an individual classifier.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from pls_logistic import PLSLogistic\n",
    "from joblib import dump, load\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define species to make a training set\n",
    "# and make a seperate folder to store\n",
    "# all the resulting data\n",
    "\n",
    "species = 'RAT'\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data')\n",
    "    \n",
    "species_data = os.path.join('data', species)\n",
    "if not os.path.exists(species_data):\n",
    "    os.mkdir(species_data)\n",
    "    \n",
    "training_data_file = os.path.join(species_data, f'{species}_training_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodel creation\n",
    "\n",
    "Below is the function that will split the training set data into balanced training groups.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multimodels(y):\n",
    "    actives = y[y == 1]\n",
    "    inactives = shuffle(y[y == 0])\n",
    "\n",
    "    splits = []\n",
    "\n",
    "    for g, df in inactives.groupby(np.arange(len(inactives)) // actives.shape[0]):\n",
    "        if df.shape[0] == actives.shape[0]:\n",
    "            split_data = df.index.tolist() + actives.index.tolist()\n",
    "        else:\n",
    "            split_data = df.index.tolist() + actives.sample(df.shape[0]).index.tolist()\n",
    "        splits.append(split_data)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep\n",
    "\n",
    "Prepare data for modeling as described above, e.g., log-transform, mean-center, variance scale.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hive/Anaconda3-2020.02/envs/cheminformatics/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALB-SERUM</th>\n",
       "      <th>ALBGLOB-SERUM</th>\n",
       "      <th>ALP-SERUM</th>\n",
       "      <th>ALT-SERUM</th>\n",
       "      <th>APTT-PLASMA</th>\n",
       "      <th>AST-SERUM</th>\n",
       "      <th>BASO-WHOLE BLOOD</th>\n",
       "      <th>BILI-SERUM</th>\n",
       "      <th>CA-SERUM</th>\n",
       "      <th>CHOL-SERUM</th>\n",
       "      <th>...</th>\n",
       "      <th>SODIUM-SERUM</th>\n",
       "      <th>SPGRAV-URINE</th>\n",
       "      <th>TRIG-SERUM</th>\n",
       "      <th>UREAN-SERUM</th>\n",
       "      <th>VOLUME-URINE</th>\n",
       "      <th>WBC-WHOLE BLOOD</th>\n",
       "      <th>BWDIFF_NORM</th>\n",
       "      <th>BWSLOPE_NORM</th>\n",
       "      <th>BWINTCEPT_NORM</th>\n",
       "      <th>SEX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USUBJID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0436RA140_001-4201</th>\n",
       "      <td>0.202789</td>\n",
       "      <td>-0.116292</td>\n",
       "      <td>-0.498723</td>\n",
       "      <td>-0.454608</td>\n",
       "      <td>-2.829391e-15</td>\n",
       "      <td>-0.382498</td>\n",
       "      <td>0.814173</td>\n",
       "      <td>-0.243798</td>\n",
       "      <td>0.201633</td>\n",
       "      <td>-1.054498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312294</td>\n",
       "      <td>1.210959</td>\n",
       "      <td>-0.391369</td>\n",
       "      <td>0.231912</td>\n",
       "      <td>-4.671374e-16</td>\n",
       "      <td>0.787130</td>\n",
       "      <td>0.103419</td>\n",
       "      <td>0.144428</td>\n",
       "      <td>0.841787</td>\n",
       "      <td>0.977177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0436RA140_001-4202</th>\n",
       "      <td>-0.229870</td>\n",
       "      <td>-0.116292</td>\n",
       "      <td>-0.498723</td>\n",
       "      <td>-0.932984</td>\n",
       "      <td>-2.829391e-15</td>\n",
       "      <td>-0.733379</td>\n",
       "      <td>-0.824371</td>\n",
       "      <td>-0.438032</td>\n",
       "      <td>-0.884264</td>\n",
       "      <td>-0.615092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.309669</td>\n",
       "      <td>-0.052634</td>\n",
       "      <td>0.669787</td>\n",
       "      <td>-0.607666</td>\n",
       "      <td>-4.671374e-16</td>\n",
       "      <td>-0.343059</td>\n",
       "      <td>0.203184</td>\n",
       "      <td>0.188971</td>\n",
       "      <td>0.794798</td>\n",
       "      <td>0.977177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0436RA140_001-4203</th>\n",
       "      <td>0.629489</td>\n",
       "      <td>-0.116292</td>\n",
       "      <td>0.394745</td>\n",
       "      <td>-0.261184</td>\n",
       "      <td>-2.829391e-15</td>\n",
       "      <td>0.033222</td>\n",
       "      <td>0.553604</td>\n",
       "      <td>-0.056759</td>\n",
       "      <td>0.605093</td>\n",
       "      <td>0.045784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.309669</td>\n",
       "      <td>0.822733</td>\n",
       "      <td>0.255440</td>\n",
       "      <td>0.231912</td>\n",
       "      <td>-4.671374e-16</td>\n",
       "      <td>0.368605</td>\n",
       "      <td>-0.034567</td>\n",
       "      <td>-0.034770</td>\n",
       "      <td>-0.040090</td>\n",
       "      <td>0.977177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0436RA140_001-4204</th>\n",
       "      <td>-0.229870</td>\n",
       "      <td>-0.116292</td>\n",
       "      <td>0.444317</td>\n",
       "      <td>0.282846</td>\n",
       "      <td>-2.829391e-15</td>\n",
       "      <td>-0.130181</td>\n",
       "      <td>-0.824371</td>\n",
       "      <td>0.123598</td>\n",
       "      <td>-1.021038</td>\n",
       "      <td>0.203619</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.933114</td>\n",
       "      <td>0.336737</td>\n",
       "      <td>-0.889860</td>\n",
       "      <td>-0.900309</td>\n",
       "      <td>-4.671374e-16</td>\n",
       "      <td>-0.189997</td>\n",
       "      <td>-0.160832</td>\n",
       "      <td>-0.165870</td>\n",
       "      <td>-1.526675</td>\n",
       "      <td>0.977177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0436RA140_001-4205</th>\n",
       "      <td>-0.229870</td>\n",
       "      <td>-0.116292</td>\n",
       "      <td>0.444317</td>\n",
       "      <td>-0.792194</td>\n",
       "      <td>-2.829391e-15</td>\n",
       "      <td>-0.048013</td>\n",
       "      <td>-0.412313</td>\n",
       "      <td>-0.243798</td>\n",
       "      <td>-1.240362</td>\n",
       "      <td>-0.572320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.309669</td>\n",
       "      <td>0.044757</td>\n",
       "      <td>0.436553</td>\n",
       "      <td>0.231912</td>\n",
       "      <td>-4.671374e-16</td>\n",
       "      <td>-1.150006</td>\n",
       "      <td>-0.110231</td>\n",
       "      <td>-0.092947</td>\n",
       "      <td>0.274589</td>\n",
       "      <td>0.977177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ALB-SERUM  ALBGLOB-SERUM  ALP-SERUM  ALT-SERUM  \\\n",
       "USUBJID                                                              \n",
       "0436RA140_001-4201   0.202789      -0.116292  -0.498723  -0.454608   \n",
       "0436RA140_001-4202  -0.229870      -0.116292  -0.498723  -0.932984   \n",
       "0436RA140_001-4203   0.629489      -0.116292   0.394745  -0.261184   \n",
       "0436RA140_001-4204  -0.229870      -0.116292   0.444317   0.282846   \n",
       "0436RA140_001-4205  -0.229870      -0.116292   0.444317  -0.792194   \n",
       "\n",
       "                     APTT-PLASMA  AST-SERUM  BASO-WHOLE BLOOD  BILI-SERUM  \\\n",
       "USUBJID                                                                     \n",
       "0436RA140_001-4201 -2.829391e-15  -0.382498          0.814173   -0.243798   \n",
       "0436RA140_001-4202 -2.829391e-15  -0.733379         -0.824371   -0.438032   \n",
       "0436RA140_001-4203 -2.829391e-15   0.033222          0.553604   -0.056759   \n",
       "0436RA140_001-4204 -2.829391e-15  -0.130181         -0.824371    0.123598   \n",
       "0436RA140_001-4205 -2.829391e-15  -0.048013         -0.412313   -0.243798   \n",
       "\n",
       "                    CA-SERUM  CHOL-SERUM  ...  SODIUM-SERUM  SPGRAV-URINE  \\\n",
       "USUBJID                                   ...                               \n",
       "0436RA140_001-4201  0.201633   -1.054498  ...      0.312294      1.210959   \n",
       "0436RA140_001-4202 -0.884264   -0.615092  ...     -0.309669     -0.052634   \n",
       "0436RA140_001-4203  0.605093    0.045784  ...     -0.309669      0.822733   \n",
       "0436RA140_001-4204 -1.021038    0.203619  ...     -0.933114      0.336737   \n",
       "0436RA140_001-4205 -1.240362   -0.572320  ...     -0.309669      0.044757   \n",
       "\n",
       "                    TRIG-SERUM  UREAN-SERUM  VOLUME-URINE  WBC-WHOLE BLOOD  \\\n",
       "USUBJID                                                                      \n",
       "0436RA140_001-4201   -0.391369     0.231912 -4.671374e-16         0.787130   \n",
       "0436RA140_001-4202    0.669787    -0.607666 -4.671374e-16        -0.343059   \n",
       "0436RA140_001-4203    0.255440     0.231912 -4.671374e-16         0.368605   \n",
       "0436RA140_001-4204   -0.889860    -0.900309 -4.671374e-16        -0.189997   \n",
       "0436RA140_001-4205    0.436553     0.231912 -4.671374e-16        -1.150006   \n",
       "\n",
       "                    BWDIFF_NORM  BWSLOPE_NORM  BWINTCEPT_NORM       SEX  \n",
       "USUBJID                                                                  \n",
       "0436RA140_001-4201     0.103419      0.144428        0.841787  0.977177  \n",
       "0436RA140_001-4202     0.203184      0.188971        0.794798  0.977177  \n",
       "0436RA140_001-4203    -0.034567     -0.034770       -0.040090  0.977177  \n",
       "0436RA140_001-4204    -0.160832     -0.165870       -1.526675  0.977177  \n",
       "0436RA140_001-4205    -0.110231     -0.092947        0.274589  0.977177  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_response_value = 0.4\n",
    "\n",
    "df = pd.read_csv(training_data_file, index_col=0)\n",
    "df = df.replace(np.inf, np.nan)\n",
    "srted_tests = df.notnull().sum().sort_values(ascending=False)\n",
    "\n",
    "good_tests = df.columns[(df.notnull().sum() / df.shape[0]) > min_response_value]\n",
    "good_tests = good_tests[~good_tests.isin(['USUBJID', 'STUDYID', 'SEX', 'STEATOSIS',\n",
    "                                         'CHOLESTASIS', 'NECROSIS', 'SPECIES', 'IS_CONTROL',\n",
    "                                         'BWDIFF', 'BWSLOPE', 'BWINTCEPT', 'MISTRESC'])]\n",
    "\n",
    "data = df[good_tests]\n",
    "data = data.apply(lambda x: x + abs(x.min()) + 1)\n",
    "data = data.applymap(math.log10)\n",
    "\n",
    "data.index = df.USUBJID\n",
    "\n",
    "le = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "data['SEX'] = le.fit_transform(df['SEX'])\n",
    "\n",
    "data = data.fillna(data.mean())\n",
    "data = pd.DataFrame(scaler.fit_transform(data), index=data.index, columns=data.columns)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models for each disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders to store different results\n",
    "\n",
    "model_folder = os.path.join(species_data, 'models')\n",
    "if not os.path.exists(model_folder):\n",
    "    os.mkdir(model_folder)\n",
    "\n",
    "    \n",
    "prediction_folder = os.path.join(species_data, 'predictions')\n",
    "if not os.path.exists(prediction_folder):\n",
    "    os.mkdir(prediction_folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation \n",
    "\n",
    "For each disease, we split the data into several subsets with balanced disease positive/disease negative animals (see above figure).  This is accomplished by splitting the data using the `creat_multimodels` function defined above, which splits the data into _n_ different groups where _n_-1 are balanced evenly sized, with the last group being the remainder and smaller than the other groups. \n",
    "\n",
    "For every subset of data, 10 models are created using varying numbers of components from 1-10.  For each componenent, models are trained either using the full subset of data and predicted (an upper bound prediction purposefully overfit) or validated using 10 fold cross validation. \n",
    "\n",
    "To keep track of model paratemers, each model is assigned an id and associated with some model parameters (e.g., number of components, training data used, etc.).  These are stored in flat file `params.csv`.\n",
    "\n",
    "Predictions are stored as either \"training predictions\" or \"cv predictions\" to distinguish between training and cross validated predictions. \n",
    "\n",
    "There are two counts below, `total_model_id`, which is unique id for every possible model made and `mdl_idx` which refers to the training groups, i.e., the subsets of models for which there should be _n_.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = ['NECROSIS', 'CHOLESTASIS', 'STEATOSIS']\n",
    "\n",
    "\n",
    "# create a different model for each disease\n",
    "for d_name in diseases:\n",
    "\n",
    "\n",
    "    disease = df[d_name]\n",
    "    disease.index = df.USUBJID\n",
    "\n",
    "\n",
    "    train_predictions = []\n",
    "    cv_predictions = []\n",
    "    total_model_id = 0\n",
    "    params = []\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for mdl_idx, mdl_cmps in enumerate(create_multimodels(disease)):\n",
    "\n",
    "        X = scaler.fit_transform(data.loc[mdl_cmps].values)\n",
    "        y = disease.loc[mdl_cmps].values\n",
    "\n",
    "\n",
    "\n",
    "        for n_cmps in list(range(1, 11)):\n",
    "\n",
    "            pls_log = PLSLogistic(n_components=n_cmps)\n",
    "            pls_log.fit(X, y)\n",
    "            pls = CalibratedClassifierCV(pls_log, cv='prefit', method='sigmoid')\n",
    "            pls.fit(X, y)\n",
    "\n",
    "            preds = pls.predict_proba(X)\n",
    "\n",
    "            train_predictions = train_predictions + list(zip(mdl_cmps, preds[:, 1], [total_model_id]*len(mdl_cmps)))\n",
    "\n",
    "            cv = model_selection.StratifiedKFold(shuffle=True, n_splits=10)\n",
    "\n",
    "\n",
    "            models.append((total_model_id, pls))\n",
    "\n",
    "            for train, test in cv.split(X, y):\n",
    "\n",
    "                train_X = X[train, :]\n",
    "                train_y = y[train]\n",
    "\n",
    "                test_X = X[test, :]\n",
    "                test_y = y[test]\n",
    "\n",
    "                pls_log_cv = PLSLogistic(n_components=n_cmps)\n",
    "                pls_log_cv.fit(train_X, train_y)\n",
    "                pls_cv = CalibratedClassifierCV(pls_log_cv, cv='prefit', method='sigmoid')\n",
    "                pls_cv.fit(train_X, train_y)\n",
    "\n",
    "                test_preds = pls_cv.predict_proba(test_X)\n",
    "                cv_predictions = cv_predictions + list(zip(np.asarray(mdl_cmps)[test], test_preds[:, 1], [total_model_id]*len(test)))\n",
    "\n",
    "\n",
    "            params.append((total_model_id, mdl_idx, n_cmps, ';'.join(mdl_cmps), ';'.join(data.columns.tolist())))\n",
    "\n",
    "            total_model_id = total_model_id + 1\n",
    "\n",
    "\n",
    "\n",
    "    preds_df = pd.DataFrame(train_predictions)\n",
    "\n",
    "    preds_df.columns = ['USUBJID', 'PREDICTION', 'ID']\n",
    "\n",
    "    cv_preds_df = pd.DataFrame(cv_predictions)\n",
    "\n",
    "    cv_preds_df.columns = ['USUBJID', 'PREDICTION', 'ID']\n",
    "\n",
    "    params_df = pd.DataFrame(params)\n",
    "\n",
    "    params_df.columns = ['ID', 'MDL_ID', 'N_COMPONENTS', 'TRAINING', 'FEATURES']\n",
    "\n",
    "\n",
    "    \n",
    "    prediction_disease_folder = os.path.join(prediction_folder, d_name)\n",
    "    model_disease_folder = os.path.join(model_folder, d_name)\n",
    "    \n",
    "    for fldr in [prediction_disease_folder, model_disease_folder]:\n",
    "        if not os.path.exists(fldr):\n",
    "            os.mkdir(fldr)\n",
    "    \n",
    "    preds_df.to_csv(os.path.join(prediction_disease_folder, 'train_predictions.csv'))\n",
    "    cv_preds_df.to_csv(os.path.join(prediction_disease_folder, 'cv_predictions.csv'))\n",
    "    \n",
    "    \n",
    "    params_df.to_csv(os.path.join(model_disease_folder, 'params.csv'))\n",
    "\n",
    "    for mdl_id, mdl in models:\n",
    "        dump(mdl, os.path.join(model_disease_folder, '{}.mdl'.format(mdl_id)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cheminformatics]",
   "language": "python",
   "name": "conda-env-cheminformatics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
